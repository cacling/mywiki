<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../web/css/common.css" type="text/css" charset="utf-8" />
<title>并行计算机组织与结构</title>
</head>
<body>
<div id="container">

<div class="seg">

<h2><a name="1.1">并行计算编程模型</a></h2>
并行编程模型是并行计算，尤其是并行软件的基础，也是并行硬件系统的导向.并行编程模型是在硬件和内存体系结构层之上的抽象概念。<br>
<br>
通用的并行编程模型：<br>
－ 共享存储模型(Shared Memory Model)<br>
－ 线程模型(Threads Model)<br>
－ 消息传递模型(Message Passing Model)<br>
－ 数据并行模型(Data Parallel Model)<br>
其它:<br>
－ 单程序多数据型(SPMD)<br>
－ 多程序多数据型(MPMD)<br>
<br>


<h3>共享存储模型(Shared Memory Model)</h3>
在共享编程模型中，任务共享统一的可以异步读写的地址空间。通过如lock，semaphore等机制来控制共享数据冲突。<br>
<img alt="" src="i/SharedMemoryModel.jpeg" width="400px"><br>
共享存储模型的优点是对于程序员来说数据没有身份的区分，不需要特别清楚任务简单数据通信。程序开发也相应的得以简化。<br>
共享存储模型的在性能上有个很突出的缺点是很难理解和管理数据的本地性问题。处理器自己的缓冲区中使用数据，使用完毕后刷新缓存写入内存，此时可能发生多个处理器使用相同数据的总线冲突。不幸的是，一般用户很难理解或控制数据的本地化问题。<br>
在共享内存平台上，本地的编译器将会把用户程序变量转换到全局地址空间中。现在市面上还没有一般的分布式内存平台的实现。然而，先前在我们概览部分提到的KSR，它就是在分布式的机器上提供了一个共享的数据平台。<br>

<h3>线程模型(Threads Model)</h3>
在并行编程的线程模型中，单个处理器可以有多个并行的执行路径。<br>
<img alt="" src="i/ThreadsModel.jpeg" width="700px"><br>
线程模型的构成如下：<br>
- 操作系统调度主程序a.out开始运行，a.out加载所有必要 的系统资源和用户资源开始执行。<br>
- a.out完成一些串行工作，然后创建一些可以被操作系统调度的并行任务(线程)去执行。<br>
- 每次线程都有自己的数据，而且共享整个a.out的资源。这样就节省了拷贝程序资源给每个线程的开销。这样线程之间可以并行执行子程序。<br>
- 线程之间通过全局内存进行通信。这个需要同步构造来确保多个线程不会同时更新同一块全局内存。<br>
- 线程执行完了就自动销毁，但是主程序a.out在应用程序完成之前一直存在，维护必要的共享资源。<br>
- 线程通常和共享内存体系结构和操作系统相关。<br>
实现：<br>
从程序的角度出发，线程的实现通常包括：<br>
1)并行代码需要调用的子程序库；<br>
2)串行或者并行源代码中的一套编译器指令。<br>
-在以上两部分中，程序员都要负责制定所有的并行机制。<br>
-线程的实现并不是什么新技术，硬件供应商已经实现了他们自己的线程版本。线程的实现机制本质上的不同使得程序员很难开发出可以移植的多线程应用程序。<br>
-不同的标准产生了两个不同的线程实现方式：POSIX线程和OpenMP<br>
POSIX线程：<br>
-基于库函数的，需要并行编码。<br>
-IEEE POSIX 1003.1c 中有具体描述。<br>
-只适用于C语言<br>
-通常是指Pthreads<br>
-大多数的硬件供应商现在为自己的线程实现加入Pthreads<br>
-十分清晰的并行，需要程序员特别关注实现的细节。<br>
OpenMP：<br>
-基于编译器指令，可以使用串行代码。<br>
-有一群计算机软硬件厂商共同定义并支持。OpenMP在1997年完成Fortran的API，于1998年完成C/C++的API<br>
-简洁而且跨平台(Unix、Windows NT)<br>
-有C/C++和Fortran的实现<br>
-使用简单，支持增量并行<br>
- 微软有自己一套独立的线程实现机制，与以上两者都不相关。<br>
-更多信息<br>
POSIX的教程computing.llnl.gov/tutorials/pthreads<br>
OpenMP的教程computing.llnl.gov/tutorials/openMP<br>

<h3>消息传递模型(Message Passing Model)</h3>
消息传递模型有以下三个特征：<br>
1)　 计算时任务集可以用他们自己的内存。多任务可以在相同的物理处理器上，同时可以访问任意数量的处理器。<br>
2)　 任务之间通过接收和发送消息来进行数据通信。<br>
3)　 数据传输通常需要每个处理器协调操作来完成。例如，发送操作有一个接受操作来配合。<br>
<img alt="" src="i/MessagePassingModel.jpeg" width="400px">
<br>
实现<br>
从编程的角度上来看，消息传递的实现通常由源代码中的子程序库构成。程序员负责决定所有的并行机制。<br>
1980年以来出现了大量的消息传递机制的库函数。这些实现本质上是不同的，这就加大了程序员开发可移植的应用程序的难度。<br>
1992年，建立了MPI讨论组，他们的首要目标就是建立消息传递实现的标准接口。<br>
消息传递接口(MPI)的第一部分于1994年完成，第二部分完成于1996年。两部分MPI规范都可以在这里下载http://www-unix.mcs.anl.gov/mpi/。<br>
MPI现在已经成为了工业界消息传递的标准了，并且代替了市面上几乎所有的其他的实现方法。大多数比较流行的并行计算机都至少实现MPI的一个标准，有些还完全满足标准2。<br>
对于共享内存体系结构，MPI的实现通常不使用网络来进行任务间的通信。替代的办法是利用共享内存来进行通信，这样可以提高性能。<br>
更多信息：<br>
MPI的教程computing.llnl.gov/tutorials/mpi；<br>

<h3>数据并行模型(Data Parallel Model)</h3>
数据并行模型有以下特性：<br>
 并行工作主要是操纵数据集。数据集一般都是像数组一样典型的通用的数据结构。<br>
 任务集都使用相同的数据结构，但是，每个任务都有自己的数据。<br>
 每个任务的工作都是相同的，例如，给每个数组元素加4。<br>
在共享内存体系结构上，所有的任务都是在全局存储空间中访问数据。在分布式存储体系结构上数据都是从任务的本地存储空间中分离出来的。<br>
<img alt="" src="i/DataParaelModel.jpeg" width="900px">
<br>
实现
使用数据并行模型编程通常都是用构造并行的数据来写程序。构造方法是调用并行数据的子函数库，然后数据并行编译器就可以识别构造时用到的编译器指令。<br>
Fortran90和95：ISO/ANSI标准扩展于Fortran77：<br>
  包含Fortran77中的所有东西；加入新的代码格式；添加新的特性集；增加程序结构和命令；增加函数、参数等变量；添加数组处理；增加新的递归函数和内部函数；和很多其他的新特性。大多数通用的并行平台都可以使用。<br>
编译器指令：可以让程序员指定数据的排列和分布。针对大多数的通用并行平台都有Fortran的实现。<br>
分布式内存模型的实现是用编译器将程序转换成标准的代码，这些代码通过调用MPI库函数来将数据分配给所有的进程。所有的消息传递对于程序员来说是不可见的。<br>
<br>
<h3>其他模型</h3>
上面提到的并行编程模型都是已经存在，而且会随着计算机软硬件的发展继续进化。除了这些之外这里还有三个更为通用的模型。<br>
混合型：<br>
这个模型中，是由两个或多个模型组合在一起实现的。<br>
当前通用的混合模型的例子就是：由消息传递模型(MPI)和线程模型(POSIX)或者共享内存模型(OpenMP)组成而成。<br>
混合模型中其他比较通用的模型是：将数据并行和消息传递组成起来。正如我们上面在数据并行模型部分提到的那样，在分布式体系结构上实现数据并行模型实际上是用消息传递的方法来为任务间传递数据的，对程序员是透明的。<br>
<h3>单程序多数据型(SPMD)</h3>
SPMD实际上是一个高层次的编程模型，是在前面提到的并行编程模型基础之上构建的。<br>
一段程序可以被所有的任务同时的执行。<br>
任务可以同时执行同一个程序中的相同或不同指令。<br>
SPMD程序通常都包含必要的逻辑，使得任务可以有条件的或者分叉的执行那些可以被执行的程序。所以任务没有必要去执行整个程序，很可能只执行一小块程序就可以了。<br>
所有的任务可能使用不同的数据。<br>
<img alt="" src="i/SPMD.jpeg" width="500px">
<br>
<h3>多程序多数据型(MPMD)</h3>
与SPMD类似，MPMD也是高层次编程模型，建立在上面提到的并行编程模型之上。<br>
MPMD应用程序多个执行程序。当程序并行执行时，每个任务可以执行相同或不同的程序作为自己的工作。所有的程序可能使用不同的数据。<br>
<img alt="" src="i/MPMD.jpeg" width="500px"><br>

<h3>小结</h3>
模型并不是为了某一个特定的机器或内存体系结构而设计的。事实上，这些模型都可以在硬件层之下实现，两个例子：<br>
－ 分布式内存机器上的共享内存模型：Kendall Square Research (KSR) ALLCACHE approach。机器的内存物理上的实现是分布式内存，但是对用户来说是一个单一的全局地址空间。一般来说，这种方法叫做虚拟共享内存。注意：尽管KSR不再应用于商务贸易方面，但是不代表其他的供应商以后不会再利用这种方式。<br>
－ 共享内存机器上的消息传递模型：MPI on SGI Origin。SGI Origin 使用 CC-NUMA类型的共享内存体系结构，这种体系结构可以使得每个任务都可以直接访问全局内存。然而，MPI发送和接受消息的功能，就像通常在网络上实现的分布式内存机器一样，实现方法相似，还十分通用。<br>
要使用哪个模型通常取决于可以获得哪个模型和个人的选择。尽管现在有模型相对于其他的来说确实有更好的实现方法，但是这里没有“最好”的模型。

</div>






<div class="seg">
<h2><a name="1.2">并行程序设计关键问题</a></h2>
- 自动化 vs. 手工并行化(Automatic vs. Manual Parallelization)<br>
- 问题可否被并行化(Can the Problem be parallelized?)<br>
- 问题分解(Partitioning) <br>
- 通信(Communications)<br>
- 同步(Synchronization)<br>
- 数据依赖(Data Dependencies)<br>
- 负载平衡(Load Balancing)<br>
- 粒度(Granularity)<br>
- 输入输出(Input/Output)<br>
<br>

<h3>自动化 vs. 手工并行化(Automatic vs. Manual Parallelization)</h3>
设计和开发并行程序是典型的人为设计的过程。程序员负责识别并行性和实现并行机制。<br>
通常，手工开发并行代码是一件费时、复杂、容易出错和迭代的过程。<br>
这些年以来，开发出多种工具帮助程序员吧串行的程序转换成并行的程序。最通用的工具类型是并行化编译器或预编译器，它们可以自动把串行化程序并行化。<br>
并行化编译器通常有以下两种工作方式：<br>
1：全自动化<br>
A）编译器分析源代码并识别代码中的并行性。<br>
B）分析包括识别并行约束，计算使用并行机制所需要的代价，判断是不是真的提高了性能。<br>
C）循环程序（do，for）是主要的自动并行化对象。<br>
2：程序员直接指定并行化<br>
A)使用编译器指令或者编译器标记，程序员清楚的告诉编译器如何来并行化代码。<br>
B)也可能在程序中的一部分使用自动并行化。<br>
如果你现在手中有串行的代码需要并行化，而且时间和预算有限的情况下自动并行化可能是更好的选择。但是在实施自动并行化之前这里有些很重要的警告应该事先告诉你。<br>
A)可能产生错误的结果<br>
B)性能可能反而下降<br>
C)人为编程的并行性灵活性更好<br>
D)只能用于代码的子程序（主要是循环）<br>
E)分析可能指出程序有依赖或者代码过于复杂而不能并行化。<br>
<br>
<br>
<h3>问题可否被并行化(Can the Problem be parallelized?)</h3>
毫无疑问，开发并行软件的第一步就是理解要并行处理的问题。如果写好了串行化代码，也有必要理解写好的这份代码。<br>
在开始花时间尝试开发问题的并行解决方案之前，首先应该判断当前的问题是否真的可以被并行。<br>
可并行化例子：为几千个独立的模块构造方法计算潜在所需开销，完成后找到花费最少的构造方法。这个例子可以被并行处理。每个模块的构造方法是彼此独立的。最小花费的计算也是可并行的问题。<br>
不可并行化的例子：计算费伯那其Fibonacci数列（1，1，2，35，8，13，21……）F(K+2)=F(K+1)+F(K).这个问题不可以并行化，以为费伯那其数列的计算中每一项都依赖与其他项，而不是独立的。K+2这个计算用到了K和K+1的结果。三个子句不可以独立的计算，因此不可以并行。<br>
识别程序中的关键点：<br>
A）了解程序中哪里做了大部分工作。大多数的科学和技术程序通常在某些地方完成了大部分的任务。<br>
B）性能分析工具在这里很有用。<br>
C）关注程序中关键点的并行，忽视那些只使用很少CPU利用率的部分程序。<br>
识别程序中的瓶颈：<br>
A)是否存在特别慢或者导致可并行的工作停止或延误的程序段？例如：I/O经常是系统瓶颈。<br>
B)有可能通过重构或者使用不同的算法可以减少或消除程序中的瓶颈。<br>
识别程序的限制因素。常见的限制是数据依赖，像Fibonacci数列中的那样。<br>
研究其他可能的算法，这可能是用来设计并行应用程序最重要的方法。<br>
<br>
<br>
<h3>问题分解(Partitioning)</h3>
设计并行程序的第一步是将问题分解成离散的可以被分配到多任务中的工作块。这就是任务分解。<br>
分解并行任务中的可计算工作的两个基本方式是：作用域分解和功能分解。<br>
1）作用域分解：<br>
在这个方法中，与问题相关的数据将会被分解。每个并行的任务只能使用部分数据。<br>
2）功能分解：<br>
在这种方式中，主要关注要被完成的计算而不是操作数据的计算。问题是根据当前一定要完成的任务划分的。每个任务完成全部工作的一部分。<br>
<br>
<br>
<h3>通信(Communications)</h3>
谁需要通信？任务之间是否需要通信取决于您要解决的问题。<br>
不需要通信的情况：<br>
1)实际上有些类型的问题可以将问题分解，并行执行时并不需要任务间共享数据。例如：假设一个图像处理的程序在处理的图像只有黑色，黑色的像素都反转成黑色。图像数据很容易就可以被分解到多个任务上，这些任务显然可以独立执行完成自己的那部分工作。<br>
2)这种类型的问题称为“使人尴尬的并行计算”，因为他们不是直截了当的并行程序。任务之间还是需要少许的通信。<br>
需要通信的情况：<br>
大多数并行应用程序没有这么简单，任务间需要彼此共享数据。例如，3D的热扩散问题，其中一个任务的温度计算要知道他周围的任务的计算数据。周围数据改变将直接影响此任务的数据。<br>
值得考虑的因素：<br>
设计任务间通信的程序时需要考虑很多十分重要的因素。<br>
1.通信开销：<br>
任务间通信肯定是需要开销的。
原本用于计算的机器时钟周期和计算资源将被用于给数据打包并传输。
频繁的任务间通信需要同步方法，同步使任务把时间花费在等待上而没有工作。
通信传输的竞争可能会占用大量的带宽，甚至影响性能。<br>
2.带宽和延迟<br>
延迟是从A点到B点发送数据需要花费的时间。通常是微秒级。
带宽是每个时间单元需要通信的数据量。通常是Mb/s或者Gb/s级别。
如果发送很多小消息的话，延迟可能会占用绝大多数的通信资源。将小消息打包成大消息一次性传递通常更加高效，也会增加有效通信带宽。<br>
3.通信的可见性<br>
在消息传递模型中，通信过程是非常清楚的，对程序员是可见的、可以控制的。
在数据并行模型中，程序员不能确切的知道任务间的通信是如何实现的，特别是在分布式内存体系结构中。<br>
4.同步通信和异步通信<br>
同步通信需要某种类型的共享数据任务间的“握手”协议。程序员可以将此过程很清楚的在程序中完成。<br>
同步通信通常是指一项任务完成后等待与他要通信的任务，后者完成计算后才可以进行通信。<br>
异步通信允许程序之间可以独立的传输数据。例如：1号任务可以在准备好后发送消息给2号任务然后立即做其他的工作，2号任务接收数据到的时间不是特别重要。<br>
异步通信通常是指不阻塞的通信，因为任务可以一边通信一边做其他任务。<br>
异步通信最适合用于交叉计算问题。<br>
5.通信的范围<br>
在设计并行代码阶段，知道哪个任务需要彼此通信是至关重要的。下面两个描述的范围可以设计成同步的也可以设计成异步的。<br>
点到点：这里包括两个任务，一个作为数据的制造者/发送者，另一个作为接收者/读数据者。<br>
聚集：这里包括多个任务的数据共享问题，每个任务都是组中的成员。<br>
6.通信效率<br>
程序员通常会根据影响通信性能的因素进行选择。这里由于篇幅限制只能提到一部分。<br>
应该使用哪种那个给定的模型？用消息传递模型为例，只有MPI实现在给定的硬件平台上可能比别的实现方法要快。<br>
应该使用哪种通信操作？正如前面提到的，异步通信操作能够提升程序的整体性能。<br>
网络媒体：有些平台可能会提供多个网络来进行通信，那么问题是那个网络是最好的呢？<br>
7.开销和复杂性<br>
<br>
<br>
<h3>同步(Synchronization)</h3>
障碍<br>
·通常障碍会影响所有的任务<br>
·每个任务完成自己的任务之后到达障碍区等待。<br>
·当所有的任务都到达障碍点后所有的任务进行同步。<br>
·执行到这里有不同的情况，通常需要做一串工作。其他的情况自动释放任务继续完成别的工作。<br>
锁和信号量<br>
·可能包括任意数量的任务。<br>
·这种方法可以串行访问全局数据和代码段。同时只可以有一个任务使用锁变量或者信号量。<br>
·第一个访问临界资源的任务设置锁，然后就可以安全的访问里面被保护的数据或代码。<br>
·其他的任务试图操作临界区，但是发现已经上锁只能等到锁的拥有者释放锁才可以操作。<br>
·阻塞和非阻塞两种方式<br>
同步通信操作<br>
·只涉及到执行通信操作的任务。<br>
·当一个任务完成通信操作，需要某种调度方法来调度其他参与通信的任务。例如：当一个任务完成发送数据的操作他必须等待接受任务的确认信息，才可以说明发送成功。<br>
·其余的在前面通信部分讨论过。<br>
<br>
<br>

<h3>数据依赖(Data Dependencies)</h3>
定义：<br>
·当程序的执行顺序影响程序的执行结果时，我们说程序间存在依赖。<br>
·不同任务同时使用相同地址的存储空间中的数据那么就存在数据依赖。<br>
·依赖问题在并行编程中是极其重要的，也是限制并行机制的主要因素。<br>
例如：<br>
·循环中的数据依赖：<br>
DO 500 J = MYSTART,MYEND<br>
　　 A(J) = A(J-1) * 2.0<br>
500 CONTINUE<br>
A(J-1) <br>的值一定要在计算A(J)值之前计算，因此A(J)的值依赖A(J-1)的值。不能并行。0<br>
如果任务2计算A(J)，任务1计算A(J-1)，想要得到正确的A(J)的值必须要：0<br>
1）分布式内存体系结构中，任务2一定要在任务1计算完A(J-1)的值后才可以计算。0<br>
2）共享内存体系结构中，任务2一定要读取任务1更新A(J-1)的值之后才可以计算。0<br>
0<br>
·循环独立数据依赖0<br>
task 1　　　　　　　 task 20<br>
------　　　　　　　 ------0<br>
X = 2　　　　　　　　 X = 40<br>
Y = X**2　　　　　 Y = X**30<br>
像前面的例子一样，这个例子也是不能并行化的，Y值依赖于：<br>
1）分布式内存体系结构——X的值在任务之间是否通信或者何时通信都存在一定的数据依赖。<br>
2）共享内存体系结构——哪个任务最后将X保存。0<br>
·当设计并行程序的时候，识别所有的数据依赖是很重要的。并行化的主要目标可能是循环，所以识别循环中的依赖问题更为重要。<br>
如何处理数据依赖<br>
·分布式内存体系结构——在同步点上需要通信数据。<br>
·共享内存体系结构——在任务之间同步读写操作。<br>
<br>
<br>
<h3>负载平衡(Load Balancing)</h3>
·负载平衡指的是使所有分布式的工作高效运行、是CPU可以保持较高的利用率较少的等待。也可以看作是将任务空闲时间最小化的方法。<br>
·对于提升系统性能来说，负载平衡是十分重要的。例如，所有的任务都要在障碍处同步，最慢的任务将决定全局的时间开销。<br>
如何获得负载平衡：<br>
·平分每个任务的工作量<br>
1)对于数组或者矩阵操作，每个任务分配相似的工作量，任务间平衡的分配数据。<br>
2)对于循环迭代每个迭代的工作量是相似的，给任务平均的分配迭代次数。<br>
3)在异质的机器上性能特点各不相同，一定要用某种性能分析工具来测试负载平衡的性能，根据结果调节工作。<br>
·动态工作分配<br>
1）即使数据平均的分配到各个任务上去，还是会存在一定的负载平衡问题。<br>
 稀疏数组——有些任务需要些非零数据而其他任务的数据基本上都是零。<br>
 自适应网格——有些任务需要规划自己的网络，而其他的任务不需要。<br>
 N-体模拟——有一些小块工作可能需要从原任务分离整合到其他任务中；这些占用小工作的进程比其他的进程需要更多的工作。<br>
2）当进程完成任务的数量很难确定或者不可以预测的时候，使用调度线程池模型可能会有所帮助。当任务完成自己的工作后，它排队去申请新的工作。<br>
3）我们有必要设计算法去检查和处理在程序中动态的发生的负载不平衡现象。<br>
<br>
<br>
<h3>粒度(Granularity)</h3>
计算通信比（译者注释：一个任务用在计算上的时间除以任务间同步通信所用的时间，比值大说明时间利用率高）<br>
·在并行计算中，粒度是用来描述计算通信比的十分量化的方法。<br>
·计算时间通常与同步事件通信的时间段不同。<br>
细粒度的并行<br>
·通信处理时只能完成很少量的可计算工作。<br>
·低的计算通信率<br>
·促进负载平衡<br>
·意味着高通信开销，降低了性能提升的可能性。<br>
·如果粒度太小很可能任务间的通信和同步所需要的花费时间比用在计算上的还长。<br>
粗粒度并行<br>
·在每次通信同步之间完成相当多的计算任务。<br>
·高计算通信率<br>
·意味着更加可能进行性能提升。<br>
·更难进行有效的负载平衡调度<br>
哪个更好？<br>
·最高效的粒度是由算法和当前硬件平台决定的。<br>
·通常情况下，通信和同步的开销很大程度上取决于执行速度，这样使用粗粒度较好。<br>
·细粒度并行机制可以减少负载不平衡所带来的开销。<br>
<br>
<br>
<h3>输入输出(Input/Output)</h3>
坏处<br>
·I/O操作通常认为是限制并行化的因素。<br>
·适用于所有平台的并行的I/O系统目前为止尚不成熟。<br>
·在所有任务都看到相同文件系统的环境中，写操作可能导致文件写覆盖。<br>
·文件服务器同时处理多线程读请求的能力将会影响写操作。<br>
·I/O一定是通过网络（NFS或者非本地文件系统）构建的，可能导致服务器性能瓶颈甚至文件服务器崩溃。<br>
优点<br>
·并行文件系统有以下几种：<br>
1）GPFS：AIX（IBM）的通用的并行文件系统。<br>
2）Lustre：Linux机群（SUN微系统）。<br>
3）PVFS/PVFS2：Linux机群的虚拟并行文件系统（Clemson/Argonne/Ohio State/等）。<br>
4）PanFS： Linux机群的Panasas ActiveScale文件系统。<br>
5）HP SFS：HP存储工作可剪裁的文件系统。Lustre是HP的基于并行文件系统(Linux全局文件系统)的产品。<br>
·并行I/O编程MPI接口规范从1996年开始发布了第二个版本MPI-2。现在也可以拿到生产商免费实现。<br>
·选项：<br>
1）如果你要访问并行文件系统，你要好好研究一下。<br>
2）规则1：尽量减少全局的I/O。<br>
3）限定工作中的某些任务的I/O操作，然后为并行任务分配通信数据。例如：任务1读取输入文件，然后和其他任务通信所需要的数据。同样，任务1从其他任务读取所需的数据后再完成写操作。<br>
4）共享文件空间的分布式内存系统，在本地完成I/O操作则不共享文件空间。例如：每个处理器可能有可以使用的临时文件空间。在自己本地操作通常要比在网络上完成I/O操作更加高效。<br>
5）为每个任务的输入输出文件创建唯一的文件名。<br>

</div>

</div>
</body>
</html>