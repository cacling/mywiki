<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../web/css/common.css" type="text/css" charset="utf-8" />
<title>并行计算的发展历史与现状</title>
</head>
<body>
<div id="container">
 并行编程模型一直是并行计算研究领域中的重点内容，它和并行计算机体系结构紧密相关。
 共享存储体系结构下的并行编程模型主要是共享变量编程模型，它具有单地址空间、编程容易、可移植性差等特点，其实现有OpenMP和Pthreads等。
 分布式存储体系结构下的并行编程模型主要有消息传递编程模型和分布式共享编程模型两种:消息传递编程模型的特点是多地址空间、编程困难、可移植性好，其实现有MPI, PVM等;
 分布式共享编程模型是指有硬件或软件的支持，在分布式体系结构下实现的具有共享变量编程模型特点的编程模型。
 后者可以分别按照硬件或软件的实现分为DSM和SVM,其实现有TreadMark和JiaJia等，目前研究热点的分割全局地址空间(PGAS)模型的研究有UPC等代表，具有很强的发展潜力。

多层次的SMP集群是由共享内存的SMP作为超节点，而超节点间采用消息传递，内存不能直接访问。
SMP集群同时具备了共享存储和分布式存储体系结构的特点，因而传统并行体系结构下的编程模型己经不再完全适用于它。
根据SMP集群多级并行结构的特点，很自然地考虑到将共享存储编程模型与分布式存储编程模型相结合。
目前国内外学术界对于SMP集群体系结构上编程模型的选择仍然存在着分歧，为此已经提出了多种方案，有的侧重性能有的侧重可移植性和易用性，孰优孰劣，尚无定论。
但从编程模型的评价标准— 计算性能和易用性综合的角度考虑，Openw 优于Thread，使得MPI+OpenMP的混合编程模型得到了广泛的应用。
混合编程模型提供了节点间和节点内的两级并行机制，它的优势在于结合了进程级的粗粒度并行(例如区域分解)和线程级的细粒度并行(如循环并行)。
实践证明，在很多情况下，其执行效率高于纯MPI或OpenMP程序，解决了一些它们无法解决的问题，



http://tech.ddvip.com/2009-04/1239102419113864.html


主要有：
1、负载平衡问题

        在MPI并行程序中可能出现负载不平衡的问题，使程序的性能受损。而在混合编程模型中，OpenMP能够很好地解决该问题，弥补了MPI的不足，从而提高并行程序的性能。
2、 MPI进程数目受限的问题

        一些应用问题存在所需进程数目与处理机数目不匹配的问题。若前者太小，则不能充分发挥机器的效率:太大，又无法执行。使用混合编程模型，首先执行MPI分解策略，启动理想数目的进程，再用OpenMP进一步分解子任务，则可以使所有处理机得到高效利用。
3、通信带宽和延迟问题

        MPI并行程序进程间的通信带宽和延迟问题可能会严重影响程序的执行性能。混合模型的程序将减少通信的次数，并且OpenMP的线程级并行具有较小的延迟，可缓解纯MPI程序的问题。
4、细粒度并行问题

        在用OpenMP来编写并行程序时，虽然粒度太小也会增加系统的开销，但相对而言远没有MPI那样严重。当应用问题的并行粒度比较小时，混合编程模型对于SMP集群这样的机器来说是个很好的选择。
        在并行编程模型的多级并行，混合编程方面国际国内都做了一些有益的探索，主要有加州伯克利分校，伊利诺伊大学，美国航天局，美国能源部的几个国家实验室，英国爱丁堡大学，德国亚琛大学以及SGI，Sun，Intel，IBM等大公司；国内则主要是中科院计算所，国防科大，北京大学，国家气象中心等单位。

http://comic.sjtu.edu.cn/thucs/GD_jsj_014b/content/chapter2/section1/part01/r1.htm

=============================================================















编程模型
Shared Memory vs Message Passing
共享存储和消息传递是目前两种主流的并行编程模型。一般认为,消息传递的可编程性不及共享存储友好

共享存储，是真正物理上的统一物理存储或者是通过系统集合所有本地存储成的统一的虚拟存储空间，都可以进行共享存储编程
消息传递，可以是物理机之间通过互联网络进行消息通信，也可以是把共享存储切割成若干独立的块，块之间进行通信

自动并行与手工并行
在SMP/DSM并行机上编译系统通常具有一定的对用户程序进行自动并行化的能力但需人工干预(制导语句，命令行选项)，针对循环(细粒度)并行
分布式内存并行机上不具备，需人工编写并行程序
并行算法的设计和并行程序的编制成为大规模并行机应用的主要障碍

DSM编程模式
建立在某种内存协议之上，通过软件或者软硬件结合的方式实现处理器间内存的共享
通过要求DSM并行程序中对内存的读写遵循一定的要求来减小维护内存一致性的开销

高性能FORTRAN(HPF)
基于数据并行的编程语言，用户通过指导语句指示编译系统将数据分布到各处理器上，并根据分布情况生成并行程序，针对Fortran90/95
适合于SMP/DSM/MPP /Cluster系统
优点：编程简单，串并行程序一致
缺点：并行过程对用户透明度不高，性能编译系统和用户对编译系统的了解程度；不同的编译器需做不通的优化，影响移植性

消息传递编程模式
并行程序由一组独立的进程组成，相互通过发送消息实现数据交换
并行应用程序开发的最底层编程方式之一，很多其他并行开发语言/工具将程序转化成消息传递类型实现。
常用的平台：PVM(Parallel Virtue Machine)和MPI(Message Passing Interface)
优点：通用性好，用PVM和MPI编写的程序可用于任何并行机；缺点：编制、调试困难，有时需对程序算法做大的改动






 多线程编程的困难

因为同一程序（进程）的多个线程共享同样的数据和资源，所以会出现同步、排队和竞争等问题，可能导致死锁、无限延迟和数据竞争等现象的发生，这些都需要我们在程序中加以解决。

安全性问题
内存共享所产生的问题
永远不发生错误的事情

活跃性问题
正确的事情最终一定会发生
死锁






<h3>多核处理器(MultiCore)</h3>
2005年 多核处理器（双核处理器）
采用单芯片多处理器（CMP，Chip Multiprocessor）设计
在单个处理器芯片内实现两个或更多的“逻辑核”。这些核都是相互独立的处理器，只是位于同一块芯片上而已。
执行核有自己的体系结构资源，并且可以与SMT技术结合
双核的CPU,在物理上(也就是实体物质上),有两个核心,就叫做物理双核。逻辑双核，就是在物理上只有一个核心，采用技术手段，使它模拟双核工作，就像一个人，完成两个人的工作任务。一个人一只手在炒菜，另一只手在洗碗.这就是两条工作线同时都在前进。用在CPU上，就是“双线程”了，也就是逻辑双核。如果炒菜和洗碗，由两个人来干，就是“物理双核”了。 逻辑双核技术,就是HT技术(超线程技术)，很显然物理双核心处理器性能要更优越。
             Intel公司的超线程技术将一个物理处理器核模拟成两个逻辑核，可并行执行两个线程从而能有效提高处理器的运行效率。
例如：
Sun的Niagara系列
IBM的Power系列
AMD的Opteron（皓龙系列 ）
Intel的Xeon（至强系列）
Tilera的TILE-Gx100
GPU
GPGPU
	Nvidia的Tesla
	AMD的Firestream
	Intel的Larabee
Cell处理器
FPGA
<img alt="" src="i/MultiCore.jpeg">


在过去，多处理器系统是昂贵和稀少的，同茶馆只有在服务器或者是科学计算设备中才会使用到多处理器系统。但是，随着多核处理器的普及，在个人电脑，甚至是手机中也会采用多处理器，这种趋势还会进一步加快。
因为。。



由处理器技术的发展而催生的多核技术带动了软件编程的变革。
以前只有在超级计算机中才能体验的并行计算目前被普及到了台式机中。
在多核技术没有产生之前,台式机中有一种多CPU的架构:对称式多处理器,在一块主板上放置多块CPU的技术,但是这种主板架构当时来讲也非常昂贵,winNT支持这种技术,一般在服务器上才被应用.
多核CPU的产生,开启了并行计算的美好篇章,普通开发者/用户都可以廉价的得到它(xp支持这种多核CPU,win98则不支持).
多核CPU架构与多CPU架构并无太大区别,只是将芯片封装的更紧密,成本更低而已.
在最新的Intel i7系列处理器上同时支持多核与超线程,这意味着处理器将扩充一倍的内核数量,如4核心CPU,将被操作系统识别为8核心.& U. x1 M) H  ]
例如在一个主板上有4个CPU插槽,每个槽插一个4核的CPU,并且每一核都具有超线程,那么将会有32个线程共同执行代码(32位windows支持CPU数量的极限),这太帅了,不是吗?5 X6 T) m3 K. i


如何看多核情况
http://www.cnblogs.com/osroot/archive/2010/05/31/1748193.html
http://wenku.baidu.com/view/fafc22f90242a8956bece4d4.html
/proc/cpuinfo 文件包含系统上每个处理器的数据段落
processor 条目包括这一逻辑处理器的唯一标识符。
physical id 条目包括每个物理封装的唯一标识符。
core id 条目保存每个内核的唯一标识符。
siblings 条目列出了位于相同物理封装中的逻辑处理器的数量。
cpu cores 条目包含位于相同物理封装中的内核数量。

拥有相同 physical id 的所有逻辑处理器共享同一个物理插座。每个 physical id 代表一个唯一的物理封装。Siblings 表示位于这一物理封装上的逻辑处理器的数量。它们可能支持也可能不支持超线程（HT）技术。每个 core id 均代表一个唯一的处理器内核。所有带有相同 core id 的逻辑处理器均位于同一个处理器内核上。如果有一个以上逻辑处理器拥有相同的 core id 和 physical id，则说明系统支持超线程（HT）技术。如果有两个或两个以上的逻辑处理器拥有相同的 physical id，但是 core id 不同，则说明这是一个多内核处理器。cpu cores 条目也可以表示是否支持多内核。

cache一致性问题
http://www.docin.com/p-351813226.html

http://tech.ddvip.com/2009-04/1239102419113864_2.html

什么是并行计算
并行计算的发展历史与现状
历史：
xxx
微处理器的三个里程碑

==================================================================

CMP是实实在在的物理核，SMT是一个核上通过特殊技术模拟多线程跑（我们常见Intel的处理器上标识的HT，是SMT的一种实现方法）
我们在技术选型上，不单要知道软件的框架上的，操作系统上的选型，而且要知道机型上的选型，不一定要深入了解其原理，有一定的了解更有助于我们选择性价比更高的架构
所以我们要明白物理核和逻辑核的区别

SMT vs CMP
单芯片多处理 CMP（Chip Multi-processing）和同时多线程 SMT(Simultaneous Threading)是开发线程级并行的两种主要技术。
在宽发射超标量结构上扩展SMT 有结构变化小，硬件利用率高，整体并行度提高显著的优点。
但本文的模拟结果显示，面对更大的线程负载，SMT 技术在性能和功耗方面的扩展性不如CMP 结构。在多个硬件核心上运行多个线程的 
CMP模式更加直观。但更多的芯片面积消耗使得每个核心的资源利用率并未提高。特别针对存储密集型的 SPEC测试程序，芯片面积开销将限制 CMP 结构的 L2 Cache容量，使得这类程序的性能低于
http://www.springerlink.com/content/y157q1u2038p3587/

CMP和SMP都有shared memory问题
http://hi.baidu.com/lu_youyou/blog/item/ffbd62ed6db7f431269791ea.html
CMP的核间通讯带宽比SMP大得多，从而不会成为性能瓶颈
CMP 的核间延迟比SMP小得多
CMP可以提供新的轻量级的一致性和同步原语
http://zh.wikipedia.org/zh/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8

在单处理器设计中，两种主要实现TLP的设计方法是芯片级多处理（CMP）芯片层多线程处理和simultaneous multithreading（SMT）。同级别层多线程处理。在更高级层中，一台计算机中有多个单独的处理器，常常运用对称多处理机（SMP）和non-uniform memory access（NUMA）非独立内存访问的方式来组织。[singlechiptlp]这些非常不同的方法，全部为了实现同一个目标，就是增加中央处理器同时处理多个线程的能力。
http://zh.wikipedia.org/wiki/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8


我们知道了SMP后，可以更好的了解CMP
CMP是指在一个芯片上集成多个微处理器核心，每个微处理器核心实质上都是一个相对简单的单线程微处理器，这多个微处理器核心可以并行地执行程序代码。具有较高线程级并行性的应用如商业应用等可以很好地利用这种结构来提高性能。
　CMP是由美国斯坦福大学提出的，其思想是将大规模并行处理器中的SMP（对称多处理器）集成到同一芯片内，各个处理器并行执行不同的进程。与CMP比较， SMT处理器结构的灵活性比较突出。但是，当半导体工艺进入0.18微米以后，线延时已经超过了门延迟，要求微处理器的设计通过划分许多规模更小、局部性更好的基本单元结构来进行。相比之下，由于CMP结构已经被划分成多个处理器核来设计，每个核都比较简单，有利于优化设计，因此更有发展前途。目前，IBM 的Power 4芯片和Sun的 MAJC5200芯片都采用了CMP结构。多核处理器可以在处理器内部共享缓存，提高缓存利用率，同时简化多处理器系统设计的复杂度。
http://news.ccw.com.cn/htm2005/20050607_172F0.htm

我们需要去等处理器增加内核，可以等主板支持更多的处理器，但是我们的业务不能等，虽然难，必须可以横向扩展来支撑更大的业务


超标量与流水线
超标量（superscalar）CPU架构，使用单颗核心来实现一种被称为指令集并行（instruction-level parallelism）的并行运算形式，它能够在相同的时钟频率下增加CPU的吞吐量。超标量处理器，通过同时分派多条指令给处理器上的冗余功能单元，可以在一个时钟周期内执行一条以上的指令。每个功能单元（functional unit）不是单独的CPU核，而是在单个CPU内的一个执行资源，例如一个ALU（Arithmetic Logic Unit，算术逻辑单元）、一个位移器（bit shifter）或一个乘法器（multiplier）。
在典型情况下，超标量CPU同时也是流水线的，它们是两种不同的性能增强技术。非流水线的超标量CPU或流水线的非超标量CPU在理论上是可能的。
流水线（pipeline，管道/管线），是一个串连在一起的数据处理元素的集合，其中的一个元素的输出是下一个元素的输入。流水线中的元素常常以并行或时间片方式执行，在这种情况下，在元素之间常常插入一些数量的缓冲存储器。
指令流水线（instruction pipelines）是与计算机相关的流水线（其他流水线有图形流水线和软件流水线等）中的一种，它被用于处理器中，允许在同一时钟周期（circuitry）内重叠执行多个指令。时钟周期通常分割成阶段，包括指令解码、算术和寄存器读取阶段，其中每个阶段每次处理一条指令。

2．超线程
Intel的超线程技术利用特殊的硬件指令，把两个逻辑内核模拟成两个物理芯片，让单个处理器核都能使用线程级并行计算，进而兼容多线程操作系统和软件，减少了CPU的闲置时间，提高的CPU的运行效率。参加下图：

采用超线程及时可在同一时间里，应用程序可以使用芯片的不同部分。虽然单线程芯片每秒钟能够处理成千上万条指令，但是在任一时刻只能够对一条指令进行操作。而超线程技术可以使芯片同时进行多线程处理，使芯片性能得到提升。
Intel表示，超线程技术让（P4）处理器在只增加5%的芯片面积的情况下，就可以换来15%~30%的效能提升。但实际上，在某些程序或未对多线程编译的程序而言，超线程反而会降低效能。除此之外，超线程CPU技术也需要主板芯片组和操作系统的配合，才能充分发挥超线程的效能。Intel公司的i865PE和i875P及更新的芯片组。微软公司的Windows XP、Windows Vista和Windows 7等操作系统都能较好地支持Intel的超线程CPU。
2002年2月Intel公司在其推出的代号为Prestonia的130nm新款至强（Xeon）处理器中首次采用超线程技术。Intel在其2003年5月21日推出的代号为Northwood的新款Intel Pentium 4 HT CPU（及绝大多数更新推出的P4处理器）中也内含超线程技术。Intel公司在其2005年5月1日推出的代号为Smithfield的EE（Extreme

Edition，极致版）系列和2006年1月16日代号为Presler的双核Pentium D处理器中也支持超线程技术。但是，Intel公司于2006年7月27日开始推出的Core 2（酷睿2）处理器，包括Solo（单核，只限笔记本电脑）、Duo（双核）、Quad（四核）及Extreme（极致）等型号，都不支持超线程。不过，Intel公司在其于2008年4月2日发布的用于笔记本和上网本的Atom（凌动）单核处理器和2008年11月17日推出的Core i7（酷睿 i7）桌面四核处理器又开始重新支持超线程技术。


多核处理器
多核，即多微处理器核心，是将两个或更多的独立处理器核封装在一个集成电路（IC）芯片中的一种方案。一般说来，多核心微处理器允许一个计算设备，在不需要将多个处理器核心分别进行独立的物理封装情况下，可以执行某些形式的线程级并行处理（Thread-Level Parallelism，TLP）。这种形式的TLP，通常被认为是芯片级别的多处理（Chip-level MultiProcessing，CMP）。
1．多核构架
按硬件层次划分，多核的种类有：
芯片级（多核芯片）：片上多核处理器（Chip Multi--Processor，CMP）就是将多个计算内核集成在一个处理器芯片中，从而提高计算能力。按计算内核的对等与否，CMP可分为同构多核（如Intel和Sun）和异构多核（如IBM）。CPU核心数据共享与同步，包括总线共享Cache结构（每个CPU内核拥有共享的二级或三级Cache，用于保存比较常用的数据，并通过连接核心的总线进行通信。例如Intel的Core 2 Due和Core i7）和基于片上互连的结构（每个CPU核心具有独立的处理单元和Cache，各个CPU核心通过交叉开关或片上网络等方式连接在一起。例如Intel的Pentium D和Core 2 Quad）。参见下图：



计算科学是理论科学、实验科学之外的第三种研究手段。计算科学与传统的两种科学，即理论科学和实验科学，并立被认为是人类认识自然的三大支柱，他们彼此相辅相成地推动科学发展与社会进步。在许多情况下，或者是理论模型复杂甚至理论尚未建立，或者实验费用昂贵甚至无法进行时，计算就成了求解问题的唯一或主要的手段。
对未知世界的探索为计算技术带来了巨大的挑战，并行计算是解决计算挑战的必由之路。随着通用集群技术和多核技术的发展，并行计算技术正逐步走向普及。
并行计算的研究涵盖并行计算机体系结构、并行算法和并行编程三个方面，其挑战在于软件和应用。
并行计算(Parallel Computing）是高性能计算(High-end Parallel Computing)又叫高端计算(Highend Computing)或超级计算(Super Computing)的核心技术。
13.6.1  为什么要做并行计算


并行计算的出现是为了适应各种应用对计算机性能和速度的不断增长要求。
1．应用需求
人类对计算及性能的要求是无止境的，从系统的角度：集成系统资源，以满足不断增长的对性能和功能的要求；从应用的角度：适当分解应用，以实现更大规模或更细致的计算更细致的计算。
2．计算速度要求
科学和工程问题的数值模拟与仿真，具有计算密集、数据密集、网络密集、及这三种混合的特点。要求在合理的时限内完成计算任务，如秒级的制造业、分钟级的短时天气预报(当天)、小时级的中期天气预报(3~10日)、尽可能快的长期天气预报(气候)、可计算的湍流模拟。
13.6.2  什么是并行计算

</div>

</div>
</body>
</html>